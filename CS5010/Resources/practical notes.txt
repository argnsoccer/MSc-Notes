References for practical:   
    Leibniz argument against mechanism (in Monadology axiom 17) - 1714 (only in context of the Chinese Room)
    Turing - Mind/Turing Test - 1950
        “The Extent to which we regard something as behaving in an intelligent manner is determined as much by our own state of mind and training 
        as by the properties of the object under consideration. If we are able to explain and predict its behaviour or if there seems to be 
        little underlying plan, we have little temptation to imagine intelligence. With the same object, therefore, it is possible that one man 
        would consider it as intelligent and another would not, the second man would have found out the rules of its behaviour”.
                           
    Alan Newell & Herbert Simon - 1955 - concluded strings of bits could stand for anything, even features of real world
        Physical Symbol System Hypothesis - A physical symbol system has the necessary and sufficient means for general intelligent Association
        By "necessary" we mean that any system that exhibits general intelligence will prove upon analysis to be a  physical symbol system. 
        By "sufficient" we mean that any physical symbol system of sufficient size can be organised to exhibit general intelligence.
        **** Intellectual issues in the history of artificial intelligence A Newell 1983 ***

        Herb Simon [Simon 1984] defines learning as ‘... any change in a system that allows it to perform better 
        the second time on repetition of the same task or on another task drawn from the same population'
                            
    Rosenblatt - Perceptron (Linear Binary Classifier) - Neural Nets - 1958/1961 - can "classify" and "learn" versus mere instruction
        Neural Nets - Not given rules like chinese room - legitimately learning - big jump in AI
        PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS 1962
        Michie's MENACE (tic-tac-toe machine using machine learning) - 1980s

    Searle - Chinese Room - 1980 
        Lawrence Davis - telephone lines and offices - 1974 
        Ned Block - China Brain - 1978

    Penrose - emperor's new mind - 1989 - human consciousness is non-algorithmic
    Penrose - Shadows of the mind - 1994

    Machine Learning - so easy to do - tensorflow/keras/pythong making it accessible to anyone
        Where is the jump from learning to "understanding?"

    As we learn more about the brain as a bioelectric &chemical machine, we also progress AI

    FUTURE/NOw - not only learning from empty (machine learning) but starting with an initial knowledge base to draw upon (not having to relearn) and be able to store
                            
    http://unesdoc.unesco.org/images/0026/002615/261563E.pdf

        1 - Existing knowledge can be utilized as “Background Knowledge”. This has benefits for the learner - in that it is 
            not forced to relearn every thing ever time.
        2 - New Learned Knowledge can be independently verified. In Turing’s world, it is possible to ask the learner after the 
            fact, “What it is that you have learned?”. The learner can then answer, for example, by emitting its learned model in 
            logic. Even if the model is not perfect, it is in a form that can be tested, debugged, and then adopted into the background 
            knowledge for future learners to use. 

            [King et al 1996].
                "A new structural alert using atoms and their bond connectivities in chemicals was able to predict mutagenicity
                - and the new alert - even though generated by an AI, was published in a peer reviewed science journal.
                Similar techniques were subsequently applied to the discovery of what makes certain chemicals behave as drugs,
                in identifying the active subcomponent of the chemicals - from a large number of reactive chemicals. Having identified 
                such a subcomponent (known as a pharmacaphore) it can be synthesised into a safe carrier molecule and be a precursor to 
                a new drug treatment. In this case, the AI tool used was capable of following Turing’s preferred route - utilizing 
                existing chemistry text- book knowledge as background knowledge, a logical representation used to input the example 
                chemicals, and a discovery emitted in a logical output form which could be understood and vetted by a chemist."
                from unesdoc source above -- talking about King et al 1996 study on rats: 
         
                "This was a strong example of AI being involved in a scientific discovery involving humans as part of the process"

            [King et al 2004]
                “Closed Loop Learning" - Nature magazine - big step forward in discovering gene expression
                autonomous AI both hypothesizing and performing experiment
                Here we have AI making scientific discoveries, in a novel way that extends our understanding of scientific method 
                (see [Gillies 1996]).

            "In her presentation at the 2016 NetExplo conference Noriko Aria demonstrated her robot (or AI software) that had 
            successfully passed the Japanese university entrance examinations in History and Mathematics. Her system Todai 
            was able to prove end of high-school level mathematical theorems [Wada et al 2015]. This was quite an achievement 
            for a machine. However, future developments might make it more challenging for human mathematicians as it is one 
            thing to make a proof, and another to understand it"

            "Many Machine Learning systems do not allow the inspection of their ‘up- dated basis’ by generating opaque (to 
            human) models. Michie characterises his machine learning definition above as that of ‘Weak Machine Learning’ and 
            goes on to define Strong Machine Learning as a system that improves its performance and can ‘communicate its internal updates in explicit symbolic form’."
            "Strong Machine Learning is, however, not what is being used for the bulk of the today’s wave of AI
            these are typically building complex models using deep networks of opaque layers of artificial neurons
            and vast numbers of training examples"

            AGAIN Where is the jump from learning to "understanding?"